#!/bin/bash

echo "This resource doesn't push to s3 buckets"
# TODO
# - Update the file with the new state
# - Push the file to S3
# - Push the state to GitHub

payload=$(mktemp /tmp/resource.XXXXXX)
cat > $payload <&0
BUCKET=$(jq -r '.source.bucket // "something"' $payload)
BUCKET_DIR=$(jq -r '.source.bucket_subfolder // ""' $payload)
export AWS_ACCESS_KEY_ID=$(jq -r '.source.aws_access_key_id // ""' $payload)
export AWS_SECRET_ACCESS_KEY=$(jq -r '.source.aws_secret_access_key// ""' $payload)
export GIT_REPO=$(jq -r '.source.repository // ""' $payload)
COMMIT_PATH=$(jq -r '.params.commit_path // ""' $payload)
STATE=$(jq -r '.params.state // ""' $payload)
DESCRIPTION=$(jq -r '.params.description // ""' $payload)
CONTEXT=$(jq -r '.params.context // ""' $payload)
TRIGGER=$(jq -r '.params.trigger // ""' $payload)

COMMIT=$(cat "${COMMIT_PATH}")
# Get the json file from S3, updated it and push it back. Race conditions apply!
KEY=$(aws s3 ls s3://$BUCKET/$BUCKET_DIR --recursive | grep .json | grep "${COMMIT}" | sort | tail -n 1 | awk '{print $4}')
if [ -z "${KEY}" ]; then
  echo "{}" > "$(date "+%s")-${COMMIT}.json"
else
  aws s3 cp s3://$BUCKET/$KEY ./
fi

FILE=$(ls *.json)
cat "${FILE}" | jq '.state= "'${STATE}'"'
cat "${FILE}" | jq '.trigger= "'${TRIGGER}'"'
cat "${FILE}" | jq '.commit_sha= "'${COMMIT}'"'
aws s3 cp "${FILE}" s3://$BUCKET/$KEY

cat >&3 <<EOF
{
  "version": { "ref": "$COMMIT" },
  "metadata": [
    { "name": "file", "value": "$FILE" }
  ]
}
EOF
